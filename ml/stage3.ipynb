{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58f58927-0562-4aee-ab52-46b531301aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import (\n",
    "    OneHotEncoder,\n",
    "    SQLTransformer,\n",
    "    StringIndexer,\n",
    "    VectorAssembler,\n",
    "    Word2Vec,\n",
    ")\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    cos,\n",
    "    radians,\n",
    "    sin,\n",
    "    sqrt,\n",
    "    to_date,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31f2925d-a16e-43f8-9d3a-d89eae81e562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: hive.metastore.uris\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/18 21:00:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/05/18 21:00:22 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/05/18 21:00:23 WARN DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.\n",
      "25/05/18 21:00:23 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "warehouse = \"project/hive/warehouse\"\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"ML_team1\")\n",
    "    .master(\"yarn\")\n",
    "    .config(\"hive.metastore.uris\", \"thrift://hadoop-02.uni.innopolis.ru:9883\")\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse)\n",
    "    .config(\"spark.sql.avro.compression.codec\", \"snappy\")\n",
    "    .config(\"spark.hadoop.hive.metastore.client.socket.timeout\", \"300\")\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52eec77e-35df-4dab-885b-dae1423d5f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+-----------+\n",
      "|      namespace|   tableName|isTemporary|\n",
      "+---------------+------------+-----------+\n",
      "|team1_projectdb|  q1_results|      false|\n",
      "|team1_projectdb|  q2_results|      false|\n",
      "|team1_projectdb|  q3_results|      false|\n",
      "|team1_projectdb|  q4_results|      false|\n",
      "|team1_projectdb|  q5_results|      false|\n",
      "|team1_projectdb|records_part|      false|\n",
      "+---------------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"USE team1_projectdb\")\n",
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1f44976-4248-4208-b92b-ef4a96ad61fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"parquet\").table(\"team1_projectdb.records_part\")\n",
    "df = df.dropna(subset=[\"review_scores_rating\"])\n",
    "df = df.sample(0.001, seed=15)\n",
    "\n",
    "df = df.withColumn(\"host_since\", to_date(col(\"host_since\").cast(\"string\"), \"yyyyMMdd\"))\n",
    "df = df.filter(col(\"review_scores_rating\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9c8d794-5292-45c0-a57c-94ba4d3b036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_amenities = SQLTransformer(\n",
    "    statement=\"\"\"\n",
    "    SELECT *, split(coalesce(amenities, ''), ',\\\\s*') AS amenities_tokens FROM __THIS__\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "word2vec = Word2Vec(\n",
    "    inputCol=\"amenities_tokens\",\n",
    "    outputCol=\"amenities_vec\",\n",
    "    vectorSize=100,  # размерность вектора\n",
    "    minCount=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab8049f7-2962-46b1-98e7-e25055d7ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoToECEFTransformer(Transformer):\n",
    "    def __init__(self, lat_col=\"latitude\", lon_col=\"longitude\", alt_col=None) -> None:\n",
    "        super().__init__()\n",
    "        self.lat_col = lat_col\n",
    "        self.lon_col = lon_col\n",
    "        self.alt_col = alt_col\n",
    "\n",
    "    def _transform(self, df: DataFrame) -> DataFrame:\n",
    "        # Constants\n",
    "        a = 6378137.0\n",
    "        e_sq = 6.69437999014e-3\n",
    "\n",
    "        # Use altitude if available, else 0\n",
    "        if self.alt_col and self.alt_col in df.columns:\n",
    "            alt = col(self.alt_col)\n",
    "        else:\n",
    "            alt = F.lit(0.0)\n",
    "\n",
    "        lat_rad = radians(col(self.lat_col))\n",
    "        lon_rad = radians(col(self.lon_col))\n",
    "\n",
    "        N = a / sqrt(1 - e_sq * sin(lat_rad) ** 2)\n",
    "\n",
    "        x = (N + alt) * cos(lat_rad) * cos(lon_rad)\n",
    "        y = (N + alt) * cos(lat_rad) * sin(lon_rad)\n",
    "        z = (N * (1 - e_sq) + alt) * sin(lat_rad)\n",
    "\n",
    "        return df.withColumn(\"x\", x).withColumn(\"y\", y).withColumn(\"z\", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cada91b-aec8-4d22-93c1-4227abdbf899",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_transformer = GeoToECEFTransformer()\n",
    "\n",
    "df = geo_transformer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbfff57a-27fa-4324-ab41-a64e416d03d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "    \"host_response_time\",\n",
    "    \"neighbourhood\",\n",
    "    \"property_type\",\n",
    "    \"room_type\",\n",
    "    \"bed_type\",\n",
    "    \"cancellation_policy\",\n",
    "    \"month\",\n",
    "]\n",
    "\n",
    "boolean_cols = [\n",
    "    \"host_is_superhost\",\n",
    "    \"host_has_profile_pic\",\n",
    "    \"host_identity_verified\",\n",
    "    \"instant_bookable\",\n",
    "    \"require_guest_profile_picture\",\n",
    "    \"kitchen\",\n",
    "    \"wifi\",\n",
    "    \"essentials\",\n",
    "    \"tv\",\n",
    "    \"air_conditioning\",\n",
    "    \"elevator\",\n",
    "    \"washer\",\n",
    "    \"hangers\",\n",
    "    \"iron\",\n",
    "    \"laptop_friendly_workspace\",\n",
    "    \"family_kid_friendly\",\n",
    "    \"hot_water\",\n",
    "    \"cable_tv\",\n",
    "    \"free_parking_on_premises\",\n",
    "    \"hair_dryer\",\n",
    "    \"smoking_allowed\",\n",
    "    \"doorman\",\n",
    "    \"dishes_and_silverware\",\n",
    "    \"buzzer_wireless_intercom\",\n",
    "    \"refrigerator\",\n",
    "]\n",
    "\n",
    "numerical_cols = [\n",
    "    \"x\",\n",
    "    \"y\",\n",
    "    \"z\",\n",
    "    \"accommodates\",\n",
    "    \"bathrooms\",\n",
    "    \"bedrooms\",\n",
    "    \"beds\",\n",
    "    \"price\",\n",
    "    \"security_deposit\",\n",
    "    \"cleaning_fee\",\n",
    "    \"guests_included\",\n",
    "    \"extra_people\",\n",
    "    \"minimum_nights\",\n",
    "    \"maximum_nights\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b05bca42-5503-4ae4-870c-b8efaca0cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers = [\n",
    "    StringIndexer(inputCol=col, outputCol=col + \"_index\", handleInvalid=\"keep\")\n",
    "    for col in categorical_cols\n",
    "]\n",
    "encoders = [\n",
    "    OneHotEncoder(inputCol=col + \"_index\", outputCol=col + \"_vec\")\n",
    "    for col in categorical_cols\n",
    "]\n",
    "\n",
    "# Список фич\n",
    "encoded_cols = [encoder.getOutputCol() for encoder in encoders]\n",
    "assembler_inputs = encoded_cols + boolean_cols + numerical_cols\n",
    "assembler_inputs = encoded_cols + boolean_cols + numerical_cols + [\"amenities_vec\"]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e340f00-0956-4b3e-9df9-15cb9f99ca95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        split_amenities,\n",
    "        word2vec,\n",
    "        geo_transformer,\n",
    "        *indexers,\n",
    "        *encoders,\n",
    "        assembler,\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline_model = pipeline.fit(df)\n",
    "df_prepared = pipeline_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f24b54f5-979c-437e-81fa-a34009dc1f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_df, test_df = df_prepared.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "train_df.select(\"features\", \"review_scores_rating\").write.mode(\"overwrite\").json(\n",
    "    \"project/data/train\",\n",
    ")\n",
    "test_df.select(\"features\", \"review_scores_rating\").write.mode(\"overwrite\").json(\n",
    "    \"project/data/test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4473db0-a896-4ec4-bc36-28fd08a50de1",
   "metadata": {},
   "source": [
    "## MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8566ad6-9205-4b17-b545-24ede62d81cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"review_scores_rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45da78c7-421c-469b-b5c1-715ba820babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 1.0])\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"review_scores_rating\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\",\n",
    ")\n",
    "r2_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"target\",  # замени на свою колонку таргета\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"r2\",\n",
    ")\n",
    "\n",
    "mae_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"target\",  # замени на свою колонку таргета\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"mae\",\n",
    ")\n",
    "cv = CrossValidator(\n",
    "    estimator=lr,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b4f0b76-a965-448f-9697-59c18c9390d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cv_model = cv.fit(train_df)\n",
    "best_model = cv_model.bestModel\n",
    "best_model.save(\"project/models/model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37b8604c-f712-4bd8-b513-4add8d5ecb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = best_model.transform(test_df)\n",
    "\n",
    "predictions.select(\"review_scores_rating\", \"prediction\").coalesce(1).write.mode(\n",
    "    \"overwrite\",\n",
    ").csv(\"project/output/model1_predictions\", header=True)\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "r2 = r2_evaluator.evaluate(predictions)\n",
    "mae = mae_evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f73261-961b-4f0e-8deb-d905b8e99298",
   "metadata": {},
   "source": [
    "## MODEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3bebb3d-c5b3-459e-b450-c89b58989032",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"review_scores_rating\",\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2e55113-ba74-41fd-acd8-df86caa13d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid_rf = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(rf.numTrees, [5, 10])\n",
    "    .addGrid(rf.maxDepth, [5, 10])\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f3c8478-6551-4c15-a7be-fee405bbc37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_rf = RegressionEvaluator(\n",
    "    labelCol=\"review_scores_rating\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\",\n",
    ")\n",
    "\n",
    "cv_rf = CrossValidator(\n",
    "    estimator=rf,\n",
    "    estimatorParamMaps=paramGrid_rf,\n",
    "    evaluator=evaluator_rf,\n",
    "    numFolds=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e25320e1-aa50-486a-a59b-986caebbb1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cv_model_rf = cv_rf.fit(train_df)\n",
    "best_model_rf = cv_model_rf.bestModel\n",
    "best_model_rf.save(\"project/models/model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90e9ed8c-6e71-4cb8-97ad-de4a6be49dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions_rf = best_model_rf.transform(test_df)\n",
    "\n",
    "predictions_rf.select(\"review_scores_rating\", \"prediction\").coalesce(1).write.mode(\n",
    "    \"overwrite\",\n",
    ").csv(\"project/output/model2_predictions\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae01a4c7-8b4b-433a-9d8e-a620fa8435f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rmse_rf = evaluator_rf.evaluate(predictions_rf)\n",
    "r2_rf = r2_evaluator.evaluate(predictions_rf)\n",
    "mae_rf = mae_evaluator.evaluate(predictions_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b76a033-7663-4b5f-bd9d-3ca68c640230",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------+-----------------+\n",
      "|model                                                                                            |RMSE             |\n",
      "+-------------------------------------------------------------------------------------------------+-----------------+\n",
      "|LinearRegressionModel: uid=LinearRegression_3fbe6bd617c4, numFeatures=217                        |7.343552085207993|\n",
      "|RandomForestRegressionModel: uid=RandomForestRegressor_63f978ac4f4f, numTrees=10, numFeatures=217|8.082929035332674|\n",
      "+-------------------------------------------------------------------------------------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    [str(best_model), rmse, r2, mae],\n",
    "    [str(best_model_rf), rmse_rf, r2_rf, mae_rf],\n",
    "]\n",
    "\n",
    "# temp = list(map(list, models.items()))\n",
    "df = spark.createDataFrame(models, [\"model\", \"RMSE\", \"R2\", \"MAE\"])\n",
    "df.show(truncate=False)\n",
    "\n",
    "# Save it to HDFS\n",
    "df.coalesce(1).write.mode(\"overwrite\").format(\"csv\").option(\"sep\", \",\").option(\n",
    "    \"header\",\n",
    "    \"true\",\n",
    ").save(\"project/output/evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685c960e-39f6-4c00-ab4b-8700d5e2fb67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26456d9-0e9a-4ef3-8d81-045bfef69526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
