{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f26456d9-0e9a-4ef3-8d81-045bfef69526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import (\n",
    "    OneHotEncoder,\n",
    "    SQLTransformer,\n",
    "    StringIndexer,\n",
    "    VectorAssembler,\n",
    "    Word2Vec,\n",
    ")\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql import DataFrame, Row, SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    cos,\n",
    "    radians,\n",
    "    sin,\n",
    "    sqrt,\n",
    "    to_date,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971ab7a0-e530-4582-ba45-1688b9ef2d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cv_model(cv_model, test_df, evaluator_rmse, evaluator_mae, model_name=\"\"):\n",
    "    results = []\n",
    "    param_maps = cv_model.getEstimatorParamMaps()\n",
    "    sub_models = cv_model.subModels\n",
    "\n",
    "    if not sub_models:\n",
    "        return []\n",
    "\n",
    "    for i, param_map in enumerate(param_maps):\n",
    "        try:\n",
    "            model = sub_models[i][0]  # берём первую модель folds\n",
    "            predictions = model.transform(test_df)\n",
    "            rmse = evaluator_rmse.evaluate(predictions)\n",
    "            mae = evaluator_mae.evaluate(predictions)\n",
    "\n",
    "            param_str = \", \".join(\n",
    "                f\"{param.name}={param_map[param]}\" for param in param_map\n",
    "            )\n",
    "\n",
    "            results.append(\n",
    "                Row(\n",
    "                    model=model_name,\n",
    "                    params=param_str,\n",
    "                    rmse=rmse,\n",
    "                    mae=mae,\n",
    "                ),\n",
    "            )\n",
    "        except Exception:\n",
    "            pass\n",
    "    return results\n",
    "\n",
    "\n",
    "class GeoToECEFTransformer(Transformer):\n",
    "    def __init__(self, lat_col=\"latitude\", lon_col=\"longitude\", alt_col=None) -> None:\n",
    "        super().__init__()\n",
    "        self.lat_col = lat_col\n",
    "        self.lon_col = lon_col\n",
    "        self.alt_col = alt_col\n",
    "\n",
    "    def _transform(self, df: DataFrame) -> DataFrame:\n",
    "        # Constants\n",
    "        a = 6378137.0\n",
    "        e_sq = 6.69437999014e-3\n",
    "\n",
    "        # Use altitude if available, else 0\n",
    "        if self.alt_col and self.alt_col in df.columns:\n",
    "            alt = col(self.alt_col)\n",
    "        else:\n",
    "            alt = F.lit(0.0)\n",
    "\n",
    "        lat_rad = radians(col(self.lat_col))\n",
    "        lon_rad = radians(col(self.lon_col))\n",
    "\n",
    "        N = a / sqrt(1 - e_sq * sin(lat_rad) ** 2)\n",
    "\n",
    "        x = (N + alt) * cos(lat_rad) * cos(lon_rad)\n",
    "        y = (N + alt) * cos(lat_rad) * sin(lon_rad)\n",
    "        z = (N * (1 - e_sq) + alt) * sin(lat_rad)\n",
    "\n",
    "        return df.withColumn(\"x\", x).withColumn(\"y\", y).withColumn(\"z\", z)\n",
    "\n",
    "\n",
    "def hdfs_delete_if_exists(hdfs_path) -> None:\n",
    "    subprocess.call([\"hdfs\", \"dfs\", \"-rm\", \"-r\", \"-f\", hdfs_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9ed16c5-413d-43af-9651-76a68d5e7ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 17:50:15,033 INFO fs.TrashPolicyDefault: Moved: 'hdfs://hadoop-02.uni.innopolis.ru:8020/user/team1/project/models/model1' to trash at: hdfs://hadoop-02.uni.innopolis.ru:8020/user/team1/.Trash/Current/user/team1/project/models/model11747666215025\n",
      "2025-05-19 17:50:16,694 INFO fs.TrashPolicyDefault: Moved: 'hdfs://hadoop-02.uni.innopolis.ru:8020/user/team1/project/models/model2' to trash at: hdfs://hadoop-02.uni.innopolis.ru:8020/user/team1/.Trash/Current/user/team1/project/models/model21747666216688\n",
      "Warning: Ignoring non-Spark config property: hive.metastore.uris\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/19 17:50:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/05/19 17:50:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/05/19 17:50:20 WARN DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.\n",
      "25/05/19 17:50:20 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "model_path = \"project/models/model1\"\n",
    "model_path2 = \"project/models/model2\"\n",
    "\n",
    "\n",
    "hdfs_delete_if_exists(model_path)\n",
    "hdfs_delete_if_exists(model_path2)\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    shutil.rmtree(model_path)\n",
    "\n",
    "if os.path.exists(model_path2):\n",
    "    shutil.rmtree(model_path2)\n",
    "\n",
    "\n",
    "warehouse = \"project/hive/warehouse\"\n",
    "\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"ML_team1\")\n",
    "    .master(\"yarn\")\n",
    "    .config(\"hive.metastore.uris\", \"thrift://hadoop-02.uni.innopolis.ru:9883\")\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse)\n",
    "    .config(\"spark.sql.avro.compression.codec\", \"snappy\")\n",
    "    .config(\"spark.hadoop.hive.metastore.client.socket.timeout\", \"300\")\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b18da638-2c1e-47b2-ab64-96d734492106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+-----------+\n",
      "|      namespace|           tableName|isTemporary|\n",
      "+---------------+--------------------+-----------+\n",
      "|team1_projectdb|  evaluation_results|      false|\n",
      "|team1_projectdb| feature_description|      false|\n",
      "|team1_projectdb|  feature_importance|      false|\n",
      "|team1_projectdb|feature_importanc...|      false|\n",
      "|team1_projectdb|feature_importanc...|      false|\n",
      "|team1_projectdb| grid_search_results|      false|\n",
      "|team1_projectdb|        model_params|      false|\n",
      "|team1_projectdb|      predictions_lr|      false|\n",
      "|team1_projectdb|      predictions_rf|      false|\n",
      "|team1_projectdb|          q1_results|      false|\n",
      "|team1_projectdb|          q2_results|      false|\n",
      "|team1_projectdb|          q3_results|      false|\n",
      "|team1_projectdb|          q4_results|      false|\n",
      "|team1_projectdb|          q5_results|      false|\n",
      "|team1_projectdb|          q6_results|      false|\n",
      "|team1_projectdb|        records_part|      false|\n",
      "+---------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"USE team1_projectdb\")\n",
    "spark.sql(\"SHOW TABLES\").show()\n",
    "\n",
    "\n",
    "df = spark.read.format(\"parquet\").table(\"team1_projectdb.records_part\")\n",
    "df = df.dropna(subset=[\"review_scores_rating\"])\n",
    "\n",
    "df = df.withColumn(\"host_since\", to_date(col(\"host_since\").cast(\"string\"), \"yyyyMMdd\"))\n",
    "df = df.filter(col(\"review_scores_rating\").isNotNull())\n",
    "df = df.sample(fraction=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "067825f7-916c-42a9-87d2-5d97a994ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_amenities = SQLTransformer(\n",
    "    statement=\"\"\"\n",
    "    SELECT *, split(coalesce(amenities, ''), ',\\\\s*') AS amenities_tokens FROM __THIS__\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "word2vec = Word2Vec(\n",
    "    inputCol=\"amenities_tokens\",\n",
    "    outputCol=\"amenities_vec\",\n",
    "    vectorSize=8,\n",
    "    minCount=1,\n",
    ")\n",
    "\n",
    "geo_transformer = GeoToECEFTransformer()\n",
    "\n",
    "df = geo_transformer.transform(df)\n",
    "\n",
    "categorical_cols = [\n",
    "    \"host_response_time\",\n",
    "    \"neighbourhood\",\n",
    "    \"property_type\",\n",
    "    \"room_type\",\n",
    "    \"bed_type\",\n",
    "    \"cancellation_policy\",\n",
    "    \"month\",\n",
    "]\n",
    "\n",
    "boolean_cols = [\n",
    "    \"host_is_superhost\",\n",
    "    \"host_has_profile_pic\",\n",
    "    \"host_identity_verified\",\n",
    "    \"instant_bookable\",\n",
    "    \"require_guest_profile_picture\",\n",
    "    \"kitchen\",\n",
    "    \"wifi\",\n",
    "    \"essentials\",\n",
    "    \"tv\",\n",
    "    \"air_conditioning\",\n",
    "    \"elevator\",\n",
    "    \"washer\",\n",
    "    \"hangers\",\n",
    "    \"iron\",\n",
    "    \"laptop_friendly_workspace\",\n",
    "    \"family_kid_friendly\",\n",
    "    \"hot_water\",\n",
    "    \"cable_tv\",\n",
    "    \"free_parking_on_premises\",\n",
    "    \"hair_dryer\",\n",
    "    \"smoking_allowed\",\n",
    "    \"doorman\",\n",
    "    \"dishes_and_silverware\",\n",
    "    \"buzzer_wireless_intercom\",\n",
    "    \"refrigerator\",\n",
    "]\n",
    "\n",
    "numerical_cols = [\n",
    "    \"x\",\n",
    "    \"y\",\n",
    "    \"z\",\n",
    "    \"accommodates\",\n",
    "    \"bathrooms\",\n",
    "    \"bedrooms\",\n",
    "    \"beds\",\n",
    "    \"price\",\n",
    "    \"security_deposit\",\n",
    "    \"cleaning_fee\",\n",
    "    \"guests_included\",\n",
    "    \"extra_people\",\n",
    "    \"minimum_nights\",\n",
    "    \"maximum_nights\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "521e202c-4520-4bfd-9092-4ded1a81e520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "indexers = [\n",
    "    StringIndexer(inputCol=col, outputCol=col + \"_index\", handleInvalid=\"keep\")\n",
    "    for col in categorical_cols\n",
    "]\n",
    "encoders = [\n",
    "    OneHotEncoder(inputCol=col + \"_index\", outputCol=col + \"_vec\")\n",
    "    for col in categorical_cols\n",
    "]\n",
    "\n",
    "\n",
    "encoded_cols = [encoder.getOutputCol() for encoder in encoders]\n",
    "assembler_inputs = encoded_cols + boolean_cols + numerical_cols + [\"amenities_vec\"]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        split_amenities,\n",
    "        word2vec,\n",
    "        geo_transformer,\n",
    "        *indexers,\n",
    "        *encoders,\n",
    "        assembler,\n",
    "    ],\n",
    ")\n",
    "pipeline_model = pipeline.fit(df)\n",
    "df_prepared = pipeline_model.transform(df)\n",
    "train_df, test_df = df_prepared.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# train_df.select(\"features\", \"review_scores_rating\").write.mode(\"overwrite\").json(\n",
    "#     \"project/data/train\",\n",
    "# )\n",
    "# test_df.select(\"features\", \"review_scores_rating\").write.mode(\"overwrite\").json(\n",
    "#     \"project/data/test\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb227a2a-e8d5-4161-86c7-d5d9f9ef17db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"review_scores_rating\")\n",
    "paramGrid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 1.0])\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"review_scores_rating\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\",\n",
    ")\n",
    "\n",
    "\n",
    "mae_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"review_scores_rating\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"mae\",\n",
    ")\n",
    "cv = CrossValidator(\n",
    "    estimator=lr,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,\n",
    "    collectSubModels=True,\n",
    ")\n",
    "\n",
    "\n",
    "cv_model = cv.fit(train_df)\n",
    "best_model = cv_model.bestModel\n",
    "best_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39f61368-c105-406b-bfd9-a222e842ab20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{Param(parent='LinearRegression_7411c9be5f09', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n",
       "  Param(parent='LinearRegression_7411c9be5f09', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0},\n",
       " {Param(parent='LinearRegression_7411c9be5f09', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n",
       "  Param(parent='LinearRegression_7411c9be5f09', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5},\n",
       " {Param(parent='LinearRegression_7411c9be5f09', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n",
       "  Param(parent='LinearRegression_7411c9be5f09', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0},\n",
       " {Param(parent='LinearRegression_7411c9be5f09', name='regParam', doc='regularization parameter (>= 0).'): 0.1,\n",
       "  Param(parent='LinearRegression_7411c9be5f09', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0},\n",
       " {Param(parent='LinearRegression_7411c9be5f09', name='regParam', doc='regularization parameter (>= 0).'): 0.1,\n",
       "  Param(parent='LinearRegression_7411c9be5f09', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5},\n",
       " {Param(parent='LinearRegression_7411c9be5f09', name='regParam', doc='regularization parameter (>= 0).'): 0.1,\n",
       "  Param(parent='LinearRegression_7411c9be5f09', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0},\n",
       " {Param(parent='LinearRegression_7411c9be5f09', name='regParam', doc='regularization parameter (>= 0).'): 1.0,\n",
       "  Param(parent='LinearRegression_7411c9be5f09', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0},\n",
       " {Param(parent='LinearRegression_7411c9be5f09', name='regParam', doc='regularization parameter (>= 0).'): 1.0,\n",
       "  Param(parent='LinearRegression_7411c9be5f09', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5},\n",
       " {Param(parent='LinearRegression_7411c9be5f09', name='regParam', doc='regularization parameter (>= 0).'): 1.0,\n",
       "  Param(parent='LinearRegression_7411c9be5f09', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.getEstimatorParamMaps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fe391bd-7917-4f1b-856c-15f9875dd4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85],\n",
       " [LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85],\n",
       " [LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85,\n",
       "  LinearRegressionModel: uid=LinearRegression_7411c9be5f09, numFeatures=85]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.subModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844c722f-b34a-4eaf-a5e7-dd99ff8cbad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
